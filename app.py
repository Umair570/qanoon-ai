import os
import sys
import json
import time
import threading
from flask import Flask, render_template, request, jsonify, Response, stream_with_context
from dotenv import load_dotenv

from langchain_groq import ChatGroq # ğŸ‘ˆ Reverted to Groq

# Ensure local imports work correctly
sys.path.append(os.getcwd()) 
load_dotenv()  

# --- API KEYS & CONFIG ---
groq_api_key = os.getenv("GROQ_API_KEY")

if not groq_api_key:
    print("âŒ ERROR: GROQ_API_KEY not found in environment.")

# Initialize LLM with Groq
try:
    llm = ChatGroq(
        model_name="llama-3.3-70b-versatile", # ğŸ‘ˆ High accuracy 70B model
        temperature=0.0,  # ğŸ‘ˆ 0.0 means ZERO creativity/hallucination. Just facts.
        api_key=groq_api_key,
        max_tokens=1024,
        max_retries=1 # ğŸ‘ˆ THE FIX: Stops silent sleep loops so it fails fast!
    )
    print("âš¡ SUCCESS: Groq AI Model Ready!")
except Exception as e:
    print(f"âŒ ERROR: Groq Initialization Failed - {e}")

rag = None
try:
    # This calls your RAGEngine class
    from backend.ai.rag_engine import RAGEngine
    rag = RAGEngine()
    
    # Render Memory-Safe Wakeup
    print("ğŸ”¥ Forcing Local FAISS Brain to wake up...")
    is_awake = False
    while not is_awake:
        try:
            rag.embeddings.embed_query("wake up")
            is_awake = True
            print("âœ… SUCCESS: Local FAISS Memory is fully awake!")
        except Exception:
            print("â³ Model is still booting. Knocking again in 5 seconds...")
            time.sleep(5)
            
except Exception as e:
    print(f"âŒ ERROR: Local AI Memory Failed - {e}")

# Keep-alive heartbeat (Critical for Hugging Face Inference API)
def keep_brain_awake():
    while True:
        time.sleep(300) 
        if rag:
            try:
                rag.embeddings.embed_query("heartbeat ping")
                print("ğŸ’“ [Heartbeat] Sent signal to keep Embedding Brain awake.")
            except Exception:
                pass 

threading.Thread(target=keep_brain_awake, daemon=True).start()

app = Flask(__name__)

def generate_groq_response(prompt):
    try:
        # Stream the response directly to the user
        for chunk in llm.stream(prompt):
            if chunk.content:
                yield chunk.content
        return  # ğŸ‘ˆ CRITICAL: Exits the generator successfully

    except Exception as e:
        error_msg = str(e).lower()
        
        # Catch Rate Limits (429) - Print ONCE and exit
        if '429' in error_msg or 'rate_limit' in error_msg:
            yield (
                "\n\n### â³ Whoa, Slow Down!\n"
                "**[Per-Minute Limit Reached]**\n"
                "I am currently analyzing a massive amount of legal documents for you! "
                "Please wait **60 seconds**, take a deep breath, and ask your question again. If still fails then daily limit reached. Try again tomorrow."
            )
            return  # ğŸ‘ˆ CRITICAL: Stops the function from looping
            
        # Generic fallback
        else:
            yield f"\n\n### âš ï¸ System Interruption\nAn unexpected error occurred: {str(e)}"
            return

@app.route('/')
def home(): return render_template('index.html')

@app.route('/consult', methods=['POST'])
def consult():
    data = request.json
    user_text = data.get('text', '').strip()
    user_lang = data.get('lang', 'en') # ğŸ‘ˆ NEW: Detect language from frontend

    context = ""
    if rag:
        try:
            # 1. THE WIDE NET: Search k=5 to ensure critical laws are caught
            docs = rag.search(user_text, k=5) 
            if docs:
                for doc in docs:
                    # 2. THE SHORT TAIL: Aggressively chop text to only 600 characters. 
                    # 5 docs * 600 chars = 3,000 characters (Safely under Groq Token Limit)
                    text_snippet = doc.get('text', '')[:600]
                    context += f"\nTEXT: {text_snippet}\n"
        except Exception as e:
             return Response(f"Memory Error: {str(e)}", mimetype='text/plain')

    # THE BULLETPROOF DECISION TREE PROMPT
    if user_lang == 'ur':
        system_prompt = (
            "You are Qanoon AI, an elite Legal Consultant specializing in Pakistani Law.\n"
            "CRITICAL INSTRUCTION: The user prefers URDU. You MUST write your ENTIRE response in formal, professional 'Adalti' (Legal) Urdu.\n\n"
            "### ğŸ§  STEP 1: INTENT EVALUATION (DO NOT print this step)\n"
            "Analyze the user's query:\n"
            "1. If it is a greeting: Respond ONLY with 'Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÛŒÚ©Ù…! Ù…ÛŒÚº Ù‚Ø§Ù†ÙˆÙ† Ø§Û’ Ø¢Ø¦ÛŒ ÛÙˆÚºØŒ Ø¢Ù¾ Ú©Ø§ Ù‚Ø§Ù†ÙˆÙ†ÛŒ Ù…Ø¹Ø§ÙˆÙ†Û” Ù…ÛŒÚº Ø¢Ù¾ Ú©ÛŒ Ú©ÛŒØ§ Ù…Ø¯Ø¯ Ú©Ø± Ø³Ú©ØªØ§ ÛÙˆÚºØŸ' and STOP.\n"
            "2. If the query is abusive, slang, or non-legal: Respond ONLY with 'ğŸ›‘ **[OFF-TOPIC]** Ù…ÛŒÚº ØµØ±Ù Ù¾Ø§Ú©Ø³ØªØ§Ù†ÛŒ Ù‚Ø§Ù†ÙˆÙ† Ø³Û’ Ù…ØªØ¹Ù„Ù‚ Ø³ÙˆØ§Ù„Ø§Øª Ú©Û’ Ø¬ÙˆØ§Ø¨Ø§Øª Ø¯Û’ Ø³Ú©ØªØ§ ÛÙˆÚºÛ”' and STOP. Do NOT add any legal analysis or citations.\n"
            "3. If it is a valid legal question: Proceed to Step 2.\n\n"
            "### ğŸ›ï¸ STEP 2: LEGAL FORMATTING (Only for valid legal questions)\n"
            "- Base your analysis STRICTLY on the provided DATA.\n"
            "- If DATA is missing/irrelevant, say: 'ğŸ›‘ **[DATA MISSING]** Ù…ÛŒØ±Û’ Ù¾Ø§Ø³ Ø§Ø³ Ø³ÙˆØ§Ù„ Ú©Ø§ Ø¬ÙˆØ§Ø¨ Ø¯ÛŒÙ†Û’ Ú©Û’ Ù„ÛŒÛ’ Ù…Ø®ØµÙˆØµ Ù‚Ø§Ù†ÙˆÙ†ÛŒ Ø­ÙˆØ§Ù„Û Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛÛŒÚº ÛÛ’Û”'\n"
            "- Use EXACTLY these two headers:\n"
            "### âš–ï¸ Ù‚Ø§Ù†ÙˆÙ†ÛŒ ØªØ¬Ø²ÛŒÛ\n"
            "(Your detailed Urdu analysis here using bullet points. Keep Section numbers in English digits, e.g., Section 302)\n"
            "### ğŸ“œ Ù‚Ø§Ù†ÙˆÙ†ÛŒ Ø­ÙˆØ§Ù„Û\n"
            "(List the specific Sections/Articles here, e.g., Section 380)\n"
            "- DO NOT add any extra citation lines at the very end. The 'Ù‚Ø§Ù†ÙˆÙ†ÛŒ Ø­ÙˆØ§Ù„Û' section is your final conclusion."
        )
    else:
        system_prompt = (
            "You are Qanoon AI, an elite Legal Consultant specializing in Pakistani Law.\n"
            "CRITICAL INSTRUCTION: The user prefers ENGLISH. You must write your entire response in professional English.\n\n"
            "### ğŸ§  STEP 1: INTENT EVALUATION (DO NOT print this step)\n"
            "Analyze the user's query:\n"
            "1. If it is a greeting: Respond ONLY with 'Greetings! I am Qanoon AI, a specialized legal assistant for Pakistani law. How can I assist you today?' and STOP.\n"
            "2. If the query is abusive, slang, or non-legal: Respond ONLY with 'ğŸ›‘ **[OFF-TOPIC]** I am Qanoon AI, a professional legal assistant. I can only assist with matters related to Pakistani law.' and STOP. Do NOT add any legal analysis or citations.\n"
            "3. If it is a valid legal question: Proceed to Step 2.\n\n"
            "### ğŸ›ï¸ STEP 2: LEGAL FORMATTING (Only for valid legal questions)\n"
            "- Base your analysis STRICTLY on the provided DATA.\n"
            "- If DATA is missing/irrelevant, say: 'ğŸ›‘ **[DATA MISSING]** I don't have the specific legal sections in my database to answer this accurately.'\n"
            "- Use EXACTLY these two headers:\n"
            "### âš–ï¸ Legal Analysis\n"
            "(Your detailed analysis here using bullet points)\n"
            "### ğŸ“œ Legal Authority\n"
            "(List the specific Sections/Articles here, e.g., Section 302 of the PPC)\n"
            "- DO NOT add any extra citation lines at the very end. The 'Legal Authority' section is your final conclusion."
        )

    full_prompt = f"{system_prompt}\n\nDATA:\n{context}\n\nQUERY: {user_text}"
    return Response(stream_with_context(generate_groq_response(full_prompt)), mimetype='text/plain')

# Lawyers database logic remains unchanged
LAWYERS_DB_PATH = os.path.join("backend", "data", "raw", "lawyers_db.json")

@app.route('/lawyers', methods=['GET'])
def get_lawyers():
    all_lawyers = []
    filtered_lawyers = []
    category = request.args.get('category', 'general').lower().strip()
    
    try:
        if os.path.exists(LAWYERS_DB_PATH):
            with open(LAWYERS_DB_PATH, 'r', encoding='utf-8') as f:
                all_lawyers = json.load(f)
        else:
            return jsonify([]) 
    except Exception:
        return jsonify([])

    if not all_lawyers:
        return jsonify([])

    if category == 'general' or not category:
        return jsonify(all_lawyers[:10])
    
    for lawyer in all_lawyers:
        lawyer_tags = [t.lower() for t in lawyer.get('tags', [])]
        lawyer_specialty = lawyer.get('specialty', '').lower()
        if category in lawyer_tags or category in lawyer_specialty:
            filtered_lawyers.append(lawyer)
    
    if not filtered_lawyers:
        return jsonify(all_lawyers[:5])
        
    return jsonify(filtered_lawyers)

if __name__ == "__main__":
    # Render deployment port binding
    app.run(host="0.0.0.0", port=int(os.environ.get("PORT", 5000)))